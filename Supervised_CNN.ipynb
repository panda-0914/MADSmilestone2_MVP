{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ian-byrne/MADSmilestone2/blob/main/Supervised_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa6L-qwlfHPf"
      },
      "source": [
        "# Supervised Learning: Clock Drawing Image Classification with Convolutional Neural Networks\n",
        "### Stacey Beck and Ian Byrne\n",
        "\n",
        "- Split data into sets of Training (x = image arrays ; y = labels), Test (~10% image arrays), and Validation (~10% of the Training). \n",
        "- Build CNN using Pytorch for Training and Test:\n",
        "  - Specify CUDA\n",
        "  - 2D convolution, Normalization (for faster training), Non-linear Activation Function (ex. RELU), Max Pooling (downsampling to reduce learned parameters).\n",
        "  - Define Layers \n",
        "  - Build Forward and backward pass\n",
        "  - Define optimizer (due to many - deep - nodes) ex) ADAM\n",
        "  - Calculate Loss (BCE)\n",
        "  - Calculate Accuracy, Precision, Recall (Confusion Matrix)\n",
        "  - Plot ROC and print Confusion Matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKcEhDBuf5ow",
        "outputId": "70060504-cd2b-46b6-bbf3-f196e0011b5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eoct7Or8ezZq",
        "outputId": "9c1f5945-aa56-4be2-8614-239164dcdb21"
      },
      "outputs": [],
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/ian-byrne/MADSmilestone2.git\n",
        "\n",
        "# Change directory into cloned repo\n",
        "%cd MADSmilestone2\n",
        "\n",
        "# List repo contents\n",
        "#!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtH9tfFdQepN",
        "outputId": "fad654a4-a2f2-46ba-85b4-49934b7c23d1"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics boto3\n",
        "\n",
        "# General Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import logging\n",
        "import os\n",
        "import boto3\n",
        "from botocore.exceptions import ClientError\n",
        "import requests\n",
        "import botocore\n",
        "import tempfile\n",
        "\n",
        "\n",
        "# Custom Libraries\n",
        "import Loading.load_data as ld\n",
        "import ImagePlayground.Images\n",
        "\n",
        "# Pytroch Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchmetrics\n",
        "from torch.nn.utils import spectral_norm\n",
        "\n",
        "# To Evaluate model\n",
        "from tqdm import tqdm\n",
        "import torchmetrics\n",
        "from torchmetrics import ConfusionMatrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# To visualize model\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from skimage.io import imread\n",
        "\n",
        "# To split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "fM_UbzqNogPC"
      },
      "outputs": [],
      "source": [
        "#!rm -rf /content/MADSmilestone2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5jwtXk7qv9-"
      },
      "source": [
        "# Build CNN Model using Pytorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nKizV2h4lMH"
      },
      "source": [
        "### Building and Training\n",
        "Architecture choices influenced from: \n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2018/12/guide-convolutional-neural-network-cnn/\n",
        "\n",
        "https://medium.datadriveninvestor.com/five-powerful-cnn-architectures-b939c9ddd57b\n",
        "\n",
        "https://towardsdatascience.com/how-does-sparse-convolution-work-3257a0a8fd1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "7OOYf4s0smrq"
      },
      "outputs": [],
      "source": [
        "# Define some of the hyperparameters and training variables\n",
        "#epochs = 2\n",
        "train_batch_size = 8\n",
        "val_batch = 4\n",
        "test_batch = 1\n",
        "learning_rate = 1e-3\n",
        "kernel_size = 3\n",
        "stride = 1\n",
        "padding = 1 #2*floor(3/2)\n",
        "weight_decay = 1e-5\n",
        "\n",
        "\n",
        "# Define file extension to use for new data saves\n",
        "extension_ = \"mod1\"\n",
        "\n",
        "# Normalize data if rgb and set rgb_val to True to convert \n",
        "normalize_ = False\n",
        "\n",
        "# Define which round to get data from\n",
        "rnd = 1\n",
        "\n",
        "# Use numpy data\n",
        "numpy_ = False \n",
        "\n",
        "# Define model extensions for naming file (which model do we want to train on)\n",
        "model_ext = \"4_fix\"\n",
        "m = 'First model'\n",
        "#m = 'pre-trained'\n",
        "#m = 'pre-trained-res'\n",
        "#m = 'resnet'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "Ypf_eiS8Eghk"
      },
      "outputs": [],
      "source": [
        "if numpy_ == True:\n",
        "  # Load numpy array files, add dimension of 1 for gray scale, and zip images and labels \n",
        "  # get zipped im label and separate label tensors\n",
        "  \n",
        "  tr_im_path = \"/content/gdrive/MyDrive/Colab Notebooks/numpy_files/Dementia_label_data/balanced_training.npy\"\n",
        "  tr_lb_path = \"/content/gdrive/MyDrive/Colab Notebooks/numpy_files/Dementia_label_data/balanced_train_labels.npy\"\n",
        "  val_im_path = \"/content/gdrive/MyDrive/Colab Notebooks/numpy_files/Dementia_label_data/val_im_nobal.npy\"\n",
        "  val_lb_path = \"/content/gdrive/MyDrive/Colab Notebooks/numpy_files/Dementia_label_data/val_labels_im_nobal.npy\"\n",
        "  tst_im_path = \"/content/gdrive/MyDrive/Colab Notebooks/numpy_files/Dementia_label_data/test_im_nobal.npy\"\n",
        "  tst_lb_path = \"/content/gdrive/MyDrive/Colab Notebooks/numpy_files/Dementia_label_data/val_labels_im_nobal.npy\"\n",
        "\n",
        "  train_set, y_train_tensor = ld.load_np_files(tr_im_path, tr_lb_path)\n",
        "  val_set, y_val_tensor = ld.load_np_files(val_im_path, val_lb_path)\n",
        "  test_set, y_test_tensor = ld.load_np_files(tst_im_path, tst_lb_path)\n",
        "  \"\"\"\n",
        "  #\n",
        "  #round_val = [1,2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "  #for rnd in round_val:\n",
        "    dataset = ResizedClocks(rnd, dictionary[rnd], transform = transforms.ToTensor())\n",
        "\n",
        "  #print(len(dataset))\n",
        "  train_size = int(0.9 * len(dataset))\n",
        "  test_size = int((len(dataset) - train_size)/2)\n",
        "  #print(train_size)\n",
        "  #print(test_size)\n",
        "\n",
        "  val_size = (len(dataset) - train_size - test_size)\n",
        "  #print(val_size)\n",
        "  train_set, val_set, test_set = torch.utils.data.random_split(dataset,[train_size, val_size, test_size] )\n",
        "  \"\"\"\n",
        "else:\n",
        "  path = '/content/MADSmilestone2/Data/Dictionaries/dementia_label_dicts/train_dict_nhat.txt'\n",
        "  cust_file = open(path, \"r\")\n",
        "  #print(cust_file.readline())\n",
        "  contents = cust_file.read()\n",
        "  dictionarytr = ast.literal_eval(contents)\n",
        "  cust_file.close()\n",
        "\n",
        "  path1 = '/content/MADSmilestone2/Data/Dictionaries/dementia_label_dicts/val_dict_nhat.txt'\n",
        "  cust_file = open(path1, \"r\")\n",
        "  #print(cust_file.readline())\n",
        "  contents = cust_file.read()\n",
        "  dictionaryv = ast.literal_eval(contents)\n",
        "  cust_file.close()\n",
        "\n",
        "  path2 = '/content/MADSmilestone2/Data/Dictionaries/dementia_label_dicts/test_dict_nhat.txt'\n",
        "  cust_file = open(path2, \"r\")\n",
        "  #print(cust_file.readline())\n",
        "  contents = cust_file.read()\n",
        "  dictionaryts = ast.literal_eval(contents)\n",
        "  cust_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54Zv5Nsk-R-U",
        "outputId": "4d95ad6a-2390-4a62-a55c-4552389c8f58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 5 length is 3181\n",
            "Round 2 length is 2525\n",
            "Round 1 length is 3379\n",
            "Round 10 length is 1660\n",
            "Round 3 length is 2021\n",
            "Round 7 length is 2444\n",
            "Round 8 length is 2123\n",
            "Round 9 length is 1966\n",
            "Round 4 length is 1968\n",
            "Round 6 length is 2733\n"
          ]
        }
      ],
      "source": [
        "for id, val in dictionarytr.items():\n",
        "  print(\"Round {} length is {}\".format(str(id), str(len(val))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kne45tSsQvFQ",
        "outputId": "4e0a99ff-53f3-4b6d-80fb-326d4f6652f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "class ResizedClocks():\n",
        "    # Resized clock drawing dataset\n",
        "\n",
        "    def __init__(self, round, round_labels, rgb=None, transform=None, images_path=None):\n",
        "\n",
        "        # Args:\n",
        "        # round (int): Round to grab images from.\n",
        "        # values (list of tuples): Corresponding values for the round.\n",
        "\n",
        "        self.round = round\n",
        "        self.vals = round_labels\n",
        "        self.images_path = images_path\n",
        "        self.transform = transform\n",
        "        self.rgb = rgb\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.vals)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        spid = self.vals[idx][0]\n",
        "        label = torch.tensor(int(self.vals[idx][1]))\n",
        "        \n",
        "        # Construct the image path\n",
        "        img_path = os.path.join(self.images_path, f\"{spid}.tif\")\n",
        "        \n",
        "        try:\n",
        "            # Load image directly from the path\n",
        "            im = Image.open(img_path)\n",
        "\n",
        "            if self.rgb:\n",
        "                #print('rgb')\n",
        "                gray = im.convert('RGB')\n",
        "            \n",
        "            else:\n",
        "                #print('gray')\n",
        "                gray = im.convert('1')\n",
        "\n",
        "            resized = gray.resize((160, 207))  # 284, 368))#(2560, 3312))\n",
        "            # resized = gray.resize((512, 662))\n",
        "            im_arr = np.float32(np.array(resized))  # .astype(float)\n",
        "\n",
        "            if self.transform:\n",
        "                im_arr = self.transform(im_arr)\n",
        "\n",
        "            return im_arr, label\n",
        "\n",
        "        except (FileNotFoundError, IOError) as e:\n",
        "            # Return None if image file is not found or corrupted\n",
        "            return None\n",
        "def collate_fn(batch):\n",
        "  \"\"\"From pytorch - way to bypass corrupt or non-existent data\"\"\"\n",
        "  batch = list(filter(lambda x: x is not None, batch))\n",
        "  return torch.utils.data.dataloader.default_collate(batch)\n",
        "# initialize transformation: data to tensor and normalize\n",
        "# Could probably resize using torch.transforms\n",
        "if normalize_ == \"True\":\n",
        "    processes = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    )\n",
        "    rgb_val = \"True\"\n",
        "else:\n",
        "    processes = transforms.ToTensor()\n",
        "    rgb_val = None\n",
        "\n",
        "\n",
        "\n",
        "# Define which round to get data from\n",
        "if numpy_ == False:\n",
        "  # Get the data from S3 and perform transformations\n",
        "  train_set = ResizedClocks(rnd, dictionarytr[rnd], transform=processes, rgb=rgb_val, images_path=images_path)\n",
        "  val_set = ResizedClocks(rnd, dictionaryv[rnd], transform=processes, rgb=rgb_val, images_path=images_path)\n",
        "  test_set = ResizedClocks(rnd, dictionaryts[rnd], transform=processes, rgb=rgb_val, images_path=images_path)\n",
        "\n",
        "\n",
        "# Define Dataloaders for the network\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size = train_batch_size, shuffle = True, num_workers = 6, collate_fn=collate_fn) \n",
        "validate_loader = torch.utils.data.DataLoader(val_set, batch_size = val_batch, shuffle = True, num_workers = 6, collate_fn=collate_fn) #64, 8,1\n",
        "\n",
        "\n",
        "# For round 10, there are some corrupt data that when batched at size 1 is not taken\n",
        "# care of by the collate function, but Nonechucks library skips the missing data and \n",
        "# moves on, replacing that missing data index with the next piece of data\n",
        "# could probably just use this in place of collate for all the loading\n",
        "if rnd == 10:\n",
        "  !pip install nonechucks\n",
        "  import nonechucks as nc\n",
        "  test_set_safe = nc.SafeDataset(test_set)\n",
        "  test_loader = torch.utils.data.DataLoader(test_set_safe, batch_size = test_batch, shuffle = False)\n",
        "\n",
        "else:\n",
        "  test_loader = torch.utils.data.DataLoader(test_set, batch_size = test_batch, shuffle = False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "RhabT4VULYLp",
        "outputId": "89c9f05e-7ee9-4614-ff21-5774e5e22188"
      },
      "outputs": [],
      "source": [
        "# Visualize the validation data if grayscale \n",
        "# Code taken and adapted from Pytorch tutorial\n",
        "#Labels \n",
        "classes = (0, 1, 2)\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    #npimg = img.numpy()\n",
        "    plt.figure(figsize=(10,15))\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "batch = 8\n",
        "# get some random training images\n",
        "dataiter = iter(validate_loader)\n",
        "images, labels = dataiter.next()\n",
        "#print(images.size())\n",
        "print(images.type())\n",
        "#images = images.unsqueeze(1)\n",
        "#print(type(np.float32(labels)))\n",
        "# show images\n",
        "ims = torchvision.utils.make_grid(images, nrow = 4)\n",
        "imshow(ims)\n",
        "# print labels\n",
        "print('Labels:')\n",
        "print('          '.join('%5s' % classes[labels[j]] for j in range(val_batch)))\n",
        "\n",
        "#Printing as RGB, just using basic pytorch dataloader likely converting to rbg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "KAovKkRXFU4j"
      },
      "outputs": [],
      "source": [
        " # Set to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def set_model(m, model_ext, device):\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "\n",
        "    if m == 'First model':\n",
        "      # Create model object \n",
        "      model = ConvNet()\n",
        "      model = model.to(device)#(float).cuda()\n",
        "      print(\"First model training on GPU\")\n",
        "\n",
        "    elif m == 'pre-trained':\n",
        "      mPATH = '/content/gdrive/MyDrive/Colab Notebooks/Models/cnn_512_662.model{}'.format(model_ext)\n",
        "      model = ConvNet()\n",
        "      model.load_state_dict(torch.load(mPATH))\n",
        "      model.to(device)\n",
        "      print('Pretrained CNN {} training on GPU'.format(model_ext))\n",
        "      \n",
        "\n",
        "    elif m == 'resnet':\n",
        "      model = models.resnet50(pretrained=True)\n",
        "      num_ftrs = model.fc.in_features\n",
        "      model.fc = nn.Linear(num_ftrs, 3)\n",
        "      model = model.to(device)\n",
        "      print('RESNET Model training on GPU')\n",
        "      \n",
        "\n",
        "    elif m == 'pre-trained-res':\n",
        "      mPATH = '/content/gdrive/MyDrive/Colab Notebooks/Models/cnn_512_662.model{}'.format(model_ext)\n",
        "      model = models.resnet50()\n",
        "      num_ftrs = model.fc.in_features\n",
        "      model.fc = nn.Linear(num_ftrs, 3)\n",
        "      model.load_state_dict(torch.load(mPATH))\n",
        "      model.to(device)\n",
        "      print('Pretained Resnet trained on our data {} training on GPU'.format(model_ext))\n",
        "\n",
        "  else:\n",
        "    print(\"CUDA is not available. Turn on GPU\")\n",
        "\n",
        "\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5xpaSNBrNR5"
      },
      "outputs": [],
      "source": [
        "\n",
        "#original size: 2560, 3312\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    \n",
        "    # without considering batch size: Input shape : (None,368, 284, 1) , parameters: (3*3*1*16+16) = 160\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 16, # one input channel gray scale, 16 filters out\n",
        "                            kernel_size = 3, stride = 1, padding = 1) #Out:(None,386, 284, 16). ### TRY kernel 7x7 padding 3\n",
        "    self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) #params: (3*3*16*32+32) = 4640                        \n",
        "    self.pool1 = nn.MaxPool2d(2, 2) #Out: (None, 184, 142, 32) \n",
        "    self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) #params: (3*3*16*32+32) = 4640    \n",
        "    self.conv4 = nn.Conv2d(in_channels = 64, out_channels = 64, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248                    \n",
        "    self.pool2 = nn.MaxPool2d(2, 2) #Output shape = (None, 92, 71, 64) \n",
        "    self.bn2 = nn.BatchNorm2d(64)  \n",
        "\n",
        "    #self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 128, \n",
        "                          #kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248 \n",
        "    self.conv6 = nn.Conv2d(in_channels = 64, out_channels = 128, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248\n",
        "    self.pool3 = nn.MaxPool2d(2, 2) #Output shape = (None, 46, 35, 128) \n",
        "    self.bn3 = nn.BatchNorm2d(128)\n",
        "    self.do2 = nn.Dropout(0.3)\n",
        "                                   \n",
        "                             \n",
        "    # Fully connected layer\n",
        "    self.fc1 = nn.Linear(128*46*35,60) #most recent original size of: 512, 662 -->64 x 82\n",
        "    self.do3 = nn.Dropout(0.4) #40 % probability  \n",
        "    #self.fc3 = nn.Linear(60, 30)\n",
        "    self.fc2 = nn.Linear(60, 3) # left with 3 for the three classes                     \n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn1(self.pool1(F.relu(self.conv2(F.relu(self.conv1(x))))))\n",
        "    x = self.bn2(self.pool2(F.relu(self.conv4(F.relu(self.conv3(x))))))\n",
        "    #x = self.bn3(self.pool3(F.relu(self.conv6(F.relu(self.conv5(x))))))\n",
        "    x = self.bn3(self.pool3(F.relu(self.conv6((x)))))\n",
        "    x = self.do2(x)\n",
        "    x = x.view(x.size(0),128*46*35)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.do3(x)\n",
        "    x = self.fc2(x)\n",
        "    return x                        \n",
        "    \n",
        "# Get model\n",
        "model = set_model(m, model_ext, device)\n",
        "\n",
        "# Print weights\n",
        "#for param in model.parameters():\n",
        "  #print(str(param.data.numpy().shape)+'\\n')\n",
        "  #print(\"weights fc1: \", model.fc1.weight)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "\n",
        "# Optimizer (can use SGD or ADAM)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)#, momentum = 0.9) #or ADAM/ momentum\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, weight_decay= weight_decay) \n",
        "\n",
        "#scheduler = lr_scheduler.StepLR(optimizer, step_size = 4, gamma=0.1)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience = 4)\n",
        "\n",
        "print(model)\n",
        "\n",
        "accuracy_stats = {\n",
        "    'train': [],\n",
        "    'val': []\n",
        "  }\n",
        "\n",
        "print(accuracy_stats)\n",
        "\n",
        "loss_stats = {\n",
        "    'train': [],\n",
        "    'val': []\n",
        "    }\n",
        "print(loss_stats)\n",
        "\n",
        "\n",
        "\n",
        "def train_val_model(epochs):\n",
        "  for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # TRAINING *****************************************************************\n",
        "\n",
        "    train_epoch_loss = 0\n",
        "    train_epoch_acc = 0\n",
        "\n",
        "    # set model in training mode \n",
        "    model.train()\n",
        "    print('\\nEpoch$ : %d'%epoch)\n",
        "    for x_train_batch, y_train_batch in tqdm(train_loader):\n",
        "      x_train_batch = x_train_batch.to(device)#(float).to(device) # for GPU support\n",
        "      y_train_batch = y_train_batch.to(device) \n",
        "\n",
        "      #print(x_train_batch.shape)\n",
        "\n",
        "      # sets gradients to 0 to prevent interference with previous epoch\n",
        "      optimizer.zero_grad()\n",
        "    \n",
        "      # Forward pass through NN\n",
        "      y_train_pred = model(x_train_batch)#.to(float)\n",
        "      train_loss = criterion(y_train_pred, y_train_batch)\n",
        "      train_acc = accuracy(y_train_pred, y_train_batch)\n",
        "\n",
        "      # Backward pass, updating weights\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Statistics\n",
        "      train_epoch_loss += train_loss.item()\n",
        "      train_epoch_acc += train_acc.item()\n",
        "\n",
        "\n",
        "    # VALIDATION****************************************************************   \n",
        "    \n",
        "    with torch.set_grad_enabled(False):\n",
        "      val_epoch_loss = 0\n",
        "      val_epoch_acc = 0\n",
        "\n",
        "      model.eval()\n",
        "      for x_val_batch, y_val_batch in tqdm(validate_loader):\n",
        "      \n",
        "        x_val_batch =  x_val_batch.to(device)#.to(float)\n",
        "        y_val_batch = y_val_batch.to(device)\n",
        "            \n",
        "        # Forward pass\n",
        "        y_val_pred = model(x_val_batch)#.to(float)   \n",
        "        val_loss = criterion(y_val_pred, y_val_batch)\n",
        "        val_acc = accuracy(y_val_pred, y_val_batch)\n",
        "            \n",
        "        val_epoch_loss += val_loss.item()\n",
        "        val_epoch_acc += val_acc.item()\n",
        "\n",
        "    # Prevent plateauing validation loss \n",
        "    #scheduler.step(val_epoch_loss/len(validate_loader))\n",
        "\n",
        "        \n",
        "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
        "    loss_stats['val'].append(val_epoch_loss/len(validate_loader))\n",
        "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
        "    accuracy_stats['val'].append(val_epoch_acc/len(validate_loader))\n",
        "                              \n",
        "    \n",
        "    print(f'Epoch {epoch+0:03}: Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(validate_loader):.5f}') \n",
        "    print(f'Train Acc: {train_epoch_acc/len(train_loader):.3f} | Val Acc: {val_epoch_acc/len(validate_loader):.3f}')\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def accuracy(y_pred, y_test):\n",
        "  # Calculating model accuracy at each epoch \n",
        "  y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "  _, y_pred_prob = torch.max(y_pred_softmax, dim = 1)\n",
        "  correct_pred = (y_pred_prob == y_test).float()\n",
        "  acc = correct_pred.sum() / len(correct_pred)\n",
        "  acc = torch.round(acc * 100)\n",
        "\n",
        "  return acc\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  train_val_model(9)\n",
        "    \n",
        "\n",
        "# added learning rate decay after 3rd epoch\n",
        "# 1st: round 1\n",
        "# 2nd: round 5\n",
        "# 3rd: round 6 best so far\n",
        "# 4th: round 7\n",
        "# 5th (model) saved training on 9\n",
        "# 6th: round 2\n",
        "# 7th round 8\n",
        "# 8th round 3\n",
        "# 9th round 4\n",
        "# 10th round 10\n",
        "\n",
        "\n",
        "#***************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITYjyxcK2a9P"
      },
      "source": [
        "# Evaluate the model using Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxkr2sXqqy6x",
        "outputId": "65bf42de-2f4e-4e1d-ec4b-f48cf94418e5"
      },
      "outputs": [],
      "source": [
        "# Calculate performance\n",
        "y_test = torch.tensor([])\n",
        "test_acc = torchmetrics.Accuracy()\n",
        "\n",
        "with torch.set_grad_enabled(False):\n",
        "  model.eval()\n",
        "  #model.to(float)\n",
        "  for batches in tqdm(test_loader):\n",
        "    x_test, y_test = batches\n",
        "    x_test = x_test.to(device)\n",
        "    y_test = y_test.to(device)\n",
        "    y_pred = model(x_test)\n",
        "    test_acc(y_pred.cpu(), y_test.cpu())\n",
        "    total_test_acc = test_acc.compute()\n",
        "  print('test acc: ', total_test_acc)\n",
        "  test_acc.reset()\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4OOWwEWrW2-"
      },
      "source": [
        "## Create Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QROmDemn_QeY",
        "outputId": "8b7faf29-39c2-48eb-ec3c-52065a83b236"
      },
      "outputs": [],
      "source": [
        "all_pred = []\n",
        "all_preds = torch.tensor([])\n",
        "y_test = torch.tensor([])\n",
        "with torch.set_grad_enabled(False):\n",
        "  model.eval()\n",
        "  for x_test_batch, y_test_batch in tqdm(test_loader):\n",
        "    x_test_batch = x_test_batch.to(device)#.to(float).to(device)\n",
        "    y_test_pred = model(x_test_batch)\n",
        "    _, y_pred_ = torch.max(y_test_pred, dim = 1)\n",
        "    #print(y_pred_)\n",
        "    all_pred.append(y_pred_.cpu().numpy())\n",
        "    all_preds = torch.cat((all_preds.cpu(), y_pred_.cpu()),dim = 0)\n",
        "    y_test = torch.cat((y_test, y_test_batch), dim = 0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "bI5PGwvU_SZq",
        "outputId": "5a011822-9e2b-4767-a7f4-539697b381f3"
      },
      "outputs": [],
      "source": [
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_test, all_pred))#.rename(columns=idx2class, index=idx2class)\n",
        "sns.heatmap(confusion_matrix_df, annot=True, fmt=\".2f\", cmap='BuGn')\n",
        "plt.title(\"Training on NHAT Labeled Data - ResNet\")\n",
        "plt.xlabel(\"prediction\")\n",
        "plt.ylabel(\"label (ground truth)\")\n",
        "plt.savefig('/content/gdrive/MyDrive/Colab Notebooks/model_charts/CMTX{}.png'.format(extension_))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqMBs_YS_U0U",
        "outputId": "c4410855-f025-4e9b-d6f5-6e4428ce1079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.08      0.15      0.11        20\n",
            "           1       0.12      0.35      0.18        17\n",
            "           2       0.89      0.62      0.73       157\n",
            "\n",
            "    accuracy                           0.55       194\n",
            "   macro avg       0.37      0.37      0.34       194\n",
            "weighted avg       0.74      0.55      0.62       194\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "#class_names = [\"Possible Dementia\", \"Likely Dementia\", \"No Dementia\"]\n",
        "class_vals = [0,1,2]\n",
        "\n",
        "cr = classification_report(y_test, all_pred, class_vals, output_dict = True)\n",
        "try:\n",
        "    cr_file = open('/content/gdrive/MyDrive/Colab Notebooks/model_charts/cr{}.txt'.format(extension_), 'wt')\n",
        "    cr_file.write(str(cr))\n",
        "    cr_file.close()\n",
        "  \n",
        "except:\n",
        "    print(\"Unable to write to file\")\n",
        "print(classification_report(y_test, all_pred, class_vals))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKR_i_oebCi2"
      },
      "source": [
        "## Save the GPU CNN Model\n",
        "Also includes loading on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "jTEwjKcbbAlJ"
      },
      "outputs": [],
      "source": [
        "# Save GPU model\n",
        "model_name = 'cnn_512_662.model{}'.format(extension_)\n",
        "PATH = \"/content/gdrive/MyDrive/Colab Notebooks/Models/{}\".format(model_name)\n",
        "torch.save(model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "wm-xL-D6bcp6",
        "outputId": "01b7e4a9-dbd7-4406-e6cc-dff033eda7a9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'# Load GPU model\\ndevice = torch.device(\"cuda\")\\nmodel = TheModelClass(*args, **kwargs)\\nmodel.load_state_dict(torch.load(PATH))\\nmodel.to(device)'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"# Load GPU model\n",
        "device = torch.device(\"cuda\")\n",
        "model = TheModelClass(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.to(device)\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCCx2unugW2d"
      },
      "source": [
        "# Visualize Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8SBwZMGgzrO"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# instantiate writer\n",
        "writer = SummaryWriter('/content/gdrive/MyDrive/Colab Notebooks/Images from model/im_pred1')\n",
        "\n",
        "\n",
        "# Add images from current dataset\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "ims = torchvision.utils.make_grid(images, nrow = 4)\n",
        "plt.imshow(ims)\n",
        "writer.add_image('4 validation images', ims)\n",
        "\n",
        "#!tensorboard --logdir=runs\n",
        "\n",
        "# Visualize the model\n",
        "writer.add_graph(model, images)\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Ouz0JVKRplZc",
        "outputId": "41cbb84b-5056-4c65-86f2-d75bb692050d"
      },
      "outputs": [],
      "source": [
        "crtxt = '/content/gdrive/MyDrive/Colab Notebooks/model_charts/cr3_hat.txt'\n",
        "cust_file = open(crtxt, \"r\")\n",
        "#print(cust_file.readline())\n",
        "contents = cust_file.read()\n",
        "dict_ = ast.literal_eval(contents)\n",
        "cust_file.close()\n",
        "df = pd.DataFrame(dict_)\n",
        "df.rename(columns = {'0': \"Possible Dementia (0)\", '1': \"Likely Dementia (1)\",\n",
        "                     '2': \"No Dementia (2)\"}, inplace = True)\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPMCLIsVZt4vJ7xjC6ZXgQi",
      "collapsed_sections": [],
      "include_colab_link": true,
      "machine_shape": "hm",
      "mount_file_id": "10WdpyFVm5G8J5AJrHPelKDpmooAreyPw",
      "name": "Supervised_CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
