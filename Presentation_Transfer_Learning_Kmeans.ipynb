{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ian-byrne/MADSmilestone2/blob/main/Presentation_Transfer_Learning_Kmeans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRmz38QaqNcd"
      },
      "source": [
        "# Transfer Learning and applying PCA to K-Means\n",
        "\n",
        "- Requires Google Colab Pro Plus. 'High-RAM' of 51GB setting to be set\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bkxj5ev_zKj",
        "outputId": "492b7a7b-0b2f-4647-aea4-a5de0562e771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'MADSmilestone2'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 814, done.\u001b[K\n",
            "remote: Counting objects: 100% (814/814), done.\u001b[K\n",
            "remote: Compressing objects: 100% (686/686), done.\u001b[K\n",
            "remote: Total 814 (delta 440), reused 272 (delta 118), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (814/814), 9.57 MiB | 10.16 MiB/s, done.\n",
            "Resolving deltas: 100% (440/440), done.\n",
            "/content/MADSmilestone2\n",
            "Analysis.ipynb\t\t      multimodel2.ipynb\n",
            "BECK_S_BYRNE_I_Final_695.pdf  presentation_CNN2_scores.ipynb\n",
            "CNN2_scores.ipynb\t      presentation_Supervised_CNN.ipynb\n",
            "Data\t\t\t      Presentation_Transfer_Learning_Kmeans.ipynb\n",
            "dataloader_tests.ipynb\t      proj_models.py\n",
            "ImagePlayground\t\t      README.md\n",
            "Labeling\t\t      scores_cnn_resnet.ipynb\n",
            "Loading\t\t\t      Supervised_CNN.ipynb\n",
            "Model_Datasets.ipynb\t      Transfer_Learning_Kmeans.ipynb\n",
            "multimodel1.ipynb\t      utils.py\n"
          ]
        }
      ],
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/ian-byrne/MADSmilestone2.git\n",
        "\n",
        "# Change directory into cloned repo\n",
        "%cd MADSmilestone2\n",
        "\n",
        "# List repo contents\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlOtXXtK8so8",
        "outputId": "1c8c77ce-1b5d-4dc3-aa3d-ae1c2d214f6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.18.48)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.5.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.48 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.21.48)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.48->boto3) (1.26.7)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.48->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.48->boto3) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.9.0+cu102)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (2.4.7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ]
        }
      ],
      "source": [
        "!pip install boto3 torchmetrics\n",
        "\n",
        "\n",
        "# Pytroch Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchmetrics\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Other Libraries\n",
        "import botocore\n",
        "import tempfile\n",
        "from tqdm import tqdm\n",
        "import boto3\n",
        "import io\n",
        "import os\n",
        "import ast\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "\n",
        "# Sklearn libraries\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from scipy.stats import mode\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "# Custom Libraries\n",
        "import Loading.load_data as ld\n",
        "from utils import open_dict\n",
        "from proj_models import ResizedClocks\n",
        "from utils import collate_fn\n",
        "from utils import set_model\n",
        "from utils import accuracy\n",
        "from proj_models import ConvNet\n",
        "from utils import train_val_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QsWRQUX6IeJ",
        "outputId": "56609d43-8fa5-45de-f1a1-c932b52221ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a587eJhXj6AN"
      },
      "outputs": [],
      "source": [
        "path = '/content/MADSmilestone2/Data/Dictionaries/dementia_label_dicts/train_dict_nhat.txt'\n",
        "cust_file = open(path, \"r\")\n",
        "#print(cust_file.readline())\n",
        "contents = cust_file.read() \n",
        "dictionarytr = ast.literal_eval(contents)\n",
        "cust_file.close()\n",
        "\n",
        "path1 = '/content/MADSmilestone2/Data/Dictionaries/dementia_label_dicts/val_dict_nhat.txt'\n",
        "cust_file = open(path1, \"r\")\n",
        "#print(cust_file.readline())\n",
        "contents = cust_file.read()\n",
        "dictionaryv = ast.literal_eval(contents)\n",
        "cust_file.close()\n",
        "\n",
        "path2 = '/content/MADSmilestone2/Data/Dictionaries/dementia_label_dicts/test_dict_nhat.txt'\n",
        "cust_file = open(path2, \"r\")\n",
        "#print(cust_file.readline())\n",
        "contents = cust_file.read()\n",
        "dictionaryts = ast.literal_eval(contents)\n",
        "cust_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbMI4s9hk5QE"
      },
      "outputs": [],
      "source": [
        "# Define some of the loader variables\n",
        "train_batch_size = 1\n",
        "val_batch = 4\n",
        "test_batch = 1\n",
        "rnd = 7\n",
        "normalize_ = True\n",
        "\n",
        "# Set to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# set model parameters to choose model for extracting features\n",
        "m = 'res50'# 'conv'\n",
        "model_ext = '4_fix'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResizedClocks():\n",
        "    # Resized clock drawing dataset\n",
        "\n",
        "    def __init__(self, round, round_labels, rgb=None, transform=None, images_path=None):\n",
        "\n",
        "        # Args:\n",
        "        # round (int): Round to grab images from.\n",
        "        # values (list of tuples): Corresponding values for the round.\n",
        "\n",
        "        self.round = round\n",
        "        self.vals = round_labels\n",
        "        self.images_path = images_path\n",
        "        self.transform = transform\n",
        "        self.rgb = rgb\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.vals)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        spid = self.vals[idx][0]\n",
        "        label = torch.tensor(int(self.vals[idx][1]))\n",
        "        \n",
        "        # Construct the image path\n",
        "        img_path = os.path.join(self.images_path, f\"{spid}.tif\")\n",
        "        \n",
        "        try:\n",
        "            # Load image directly from the path\n",
        "            im = Image.open(img_path)\n",
        "\n",
        "            if self.rgb:\n",
        "                #print('rgb')\n",
        "                gray = im.convert('RGB')\n",
        "            \n",
        "            else:\n",
        "                #print('gray')\n",
        "                gray = im.convert('1')\n",
        "\n",
        "            resized = gray.resize((160, 207))  # 284, 368))#(2560, 3312))\n",
        "            # resized = gray.resize((512, 662))\n",
        "            im_arr = np.float32(np.array(resized))  # .astype(float)\n",
        "\n",
        "            if self.transform:\n",
        "                im_arr = self.transform(im_arr)\n",
        "\n",
        "            return im_arr, label\n",
        "\n",
        "        except (FileNotFoundError, IOError) as e:\n",
        "            # Return None if image file is not found or corrupted\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "  \"\"\"From pytorch - way to bypass corrupt or non-existent data\"\"\"\n",
        "  batch = list(filter(lambda x: x is not None, batch))\n",
        "  return torch.utils.data.dataloader.default_collate(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialize transformation: data to tensor and normalize\n",
        "# Could probably resize using torch.transforms\n",
        "if normalize_ == \"True\":\n",
        "    processes = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    )\n",
        "    rgb_val = \"True\"\n",
        "else:\n",
        "    processes = transforms.ToTensor()\n",
        "    rgb_val = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAj2BS4Xnkm9"
      },
      "outputs": [],
      "source": [
        "train_set = ResizedClocks(rnd, dictionarytr[rnd], transform=processes, rgb=rgb_val, images_path=images_path)\n",
        "val_set = ResizedClocks(rnd, dictionaryv[rnd], transform=processes, rgb=rgb_val, images_path=images_path)\n",
        "test_set = ResizedClocks(rnd, dictionaryts[rnd], transform=processes, rgb=rgb_val, images_path=images_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_l6UFWDnqw6"
      },
      "outputs": [],
      "source": [
        "# Define Dataloaders for the network\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size = train_batch_size, shuffle = True, num_workers = 6, collate_fn=collate_fn) \n",
        "validate_loader = torch.utils.data.DataLoader(val_set, batch_size = val_batch, shuffle = True, num_workers = 6, collate_fn=collate_fn) #64, 8,1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCrPRAyynrMy"
      },
      "outputs": [],
      "source": [
        "# For round 10, there are some corrupt data that when batched at size 1 is not taken\n",
        "# care of by the collate function, but Nonechucks library skips the missing data and \n",
        "# moves on, replacing that missing data index with the next piece of data\n",
        "# could probably just use this in place of collate for all the loading\n",
        "if rnd == 10:\n",
        "  !pip install nonechucks\n",
        "  import nonechucks as nc\n",
        "  test_set_safe = nc.SafeDataset(test_set)\n",
        "  test_loader = torch.utils.data.DataLoader(test_set_safe, batch_size = test_batch, shuffle = False)\n",
        "else:\n",
        "  test_loader = torch.utils.data.DataLoader(test_set, batch_size = test_batch, shuffle = False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6m6xdD8plDQ"
      },
      "outputs": [],
      "source": [
        "#original size: 2560, 3312\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    \n",
        "    # without considering batch size: Input shape : (None,368, 284, 1) , parameters: (3*3*1*16+16) = 160\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 16, # one input channel gray scale, 16 filters out\n",
        "                            kernel_size = 3, stride = 1, padding = 1) #Out:(None,386, 284, 16). ### TRY kernel 7x7 padding 3\n",
        "    self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) #params: (3*3*16*32+32) = 4640                        \n",
        "    self.pool1 = nn.MaxPool2d(2, 2) #Out: (None, 184, 142, 32) \n",
        "    self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) #params: (3*3*16*32+32) = 4640    \n",
        "    self.conv4 = nn.Conv2d(in_channels = 64, out_channels = 64, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248                    \n",
        "    self.pool2 = nn.MaxPool2d(2, 2) #Output shape = (None, 92, 71, 64) \n",
        "    self.bn2 = nn.BatchNorm2d(64)  \n",
        "\n",
        "    #self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 128, \n",
        "                          #kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248 \n",
        "    self.conv6 = nn.Conv2d(in_channels = 64, out_channels = 128, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248\n",
        "    self.pool3 = nn.MaxPool2d(2, 2) #Output shape = (None, 46, 35, 128) \n",
        "    self.bn3 = nn.BatchNorm2d(128)\n",
        "    self.do2 = nn.Dropout(0.3)\n",
        "                                   \n",
        "                             \n",
        "    # Fully connected layer\n",
        "    self.fc1 = nn.Linear(128*46*35,60) #most recent original size of: 512, 662 -->64 x 82\n",
        "    self.do3 = nn.Dropout(0.4) #40 % probability  \n",
        "    #self.fc3 = nn.Linear(60, 30)\n",
        "    self.fc2 = nn.Linear(60, 3) # left with 3 for the three classes                     \n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn1(self.pool1(F.relu(self.conv2(F.relu(self.conv1(x))))))\n",
        "    x = self.bn2(self.pool2(F.relu(self.conv4(F.relu(self.conv3(x))))))\n",
        "    #x = self.bn3(self.pool3(F.relu(self.conv6(F.relu(self.conv5(x))))))\n",
        "    x = self.bn3(self.pool3(F.relu(self.conv6((x)))))\n",
        "    x = self.do2(x)\n",
        "    x = x.view(x.size(0),128*46*35)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.do3(x)\n",
        "    x = self.fc2(x)\n",
        "    return x              "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "b1d9d979190c4543b40fb71308fff837",
            "1090d3fa925d4038837812e7a5fad35e",
            "806838574b924a878709e07968ee291f",
            "626cd0c21f97410f8241b17b208deba9",
            "9fd09081e3a546ac8f42e8b9190f85e3",
            "1d52bdba857c406b99d5140ea8ddce7f",
            "1d9dee4b836c4c85a65dea21d754a907",
            "33453b104cda4358b73224ae49a9b24c",
            "e5143400f47143f4ba30c6393bc5a015",
            "1e58225a2f15430398fb0e4c50939172",
            "c6b11ef609f54bd29ec8f0975933eccb"
          ]
        },
        "id": "VhrEvCuYrXAZ",
        "outputId": "0d568aca-8d29-45ed-a738-3312f47475be"
      },
      "outputs": [],
      "source": [
        "# Get model\n",
        "if m == 'conv':\n",
        "  model_ext = '4_fix'\n",
        "  mPATH = '/content/gdrive/MyDrive/Colab Notebooks/Models/cnn_512_662.model{}'.format(model_ext)\n",
        "  model = ConvNet()\n",
        "  #model.load_state_dict(torch.load(mPATH, map_location=torch.device('cpu')))\n",
        "  model.load_state_dict(torch.load(mPATH))\n",
        "  model.to(device)\n",
        "  print(\"conv\")\n",
        "\n",
        "if m == 'res50':\n",
        "  model = models.resnet50(pretrained = True)\n",
        "  num_ftrs = model.fc.in_features\n",
        "  model.fc = nn.Linear(num_ftrs, 3)\n",
        "  model = model.to(device)\n",
        "  print(\"res 50 pretrained\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rAWdxiWkyyU"
      },
      "source": [
        "# Transfer Learning with PCA and K-Means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w5Y1KDj3dz2"
      },
      "source": [
        "### Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ij-c1MqHAFzc"
      },
      "outputs": [],
      "source": [
        "# Remove prediction layer (last fc layer)\n",
        "if m == 'res50':\n",
        "  model_1 = nn.Sequential(*list(model.children())[:-1])\n",
        "else:\n",
        "  model_1 = nn.Sequential(*list(model.children())[:-3]) # removes last FCs of CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPSmio_aA2RF",
        "outputId": "ef133dc0-e7e2-45b8-b932-03a49d4e0d77"
      },
      "outputs": [],
      "source": [
        "# Use model for evaluation\n",
        "model_1.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GDqbInOVXbO"
      },
      "outputs": [],
      "source": [
        "# Hold the data sets\n",
        "X = []\n",
        "y_train=[]\n",
        "for x, lb in tqdm(test_loader):\n",
        "  print(x.size)\n",
        "  # Get image features from model\n",
        "  x = x.to(device)\n",
        "  preds = model_1(x)\n",
        "  X.append(preds.cpu())\n",
        "  y_train.append(lb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCrc8SzhOZXL",
        "outputId": "80f32eea-07b1-41e3-8995-00eb05a34af4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of Tensor Array X:  torch.Size([1, 2048, 1, 1])\n",
            "Shape of Numpy Array X:  (254, 1, 2048, 1, 1)\n",
            "Shape of y:  (254,)\n",
            "Type of y:  <class 'numpy.ndarray'>\n",
            "Shape of flattened numpy array X:  (254, 2048)\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of Tensor Array X: \", X[0].shape)\n",
        "x_ = np.array([t.cpu().detach().numpy() for t in X])\n",
        "print(\"Shape of Numpy Array X: \", x_.shape)\n",
        "y_train_ = np.array(y_train)\n",
        "print(\"Shape of y: \", (y_train_).shape)\n",
        "print(\"Type of y: \", type(y_train_))\n",
        "w = x_.reshape(x_.shape[0], -1)\n",
        "print(\"Shape of flattened numpy array X: \", w.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYgzyqc33hee"
      },
      "source": [
        "### Perform PCA on data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEf9iFTxSaJK"
      },
      "outputs": [],
      "source": [
        "def run_pca(w):\n",
        "  # Instantite PCA model\n",
        "  variance = 0.98 #The higher the variance the more accurate, more dimensions remain\n",
        "  pca = PCA(variance)\n",
        "\n",
        "  pca.fit(w) #fit the data \n",
        "  print(\"Number of components before PCA: \", w.shape[1])\n",
        "  print(\"Number of components after PCA {}:\".format(variance), pca.n_components_)\n",
        "\n",
        "  # Transform into new features\n",
        "  w_pca = pca.transform(w)\n",
        "  print(\"Dim after PCA: \", w_pca.shape)\n",
        "  return w_pca\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYK243KP3pAz"
      },
      "source": [
        "### Predict number of clusters using KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZB7kHJKPc1J",
        "outputId": "64bf17fb-4c2b-4a83-8de3-a0821555e62a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of components before PCA:  2048\n",
            "Number of components after PCA 0.98: 114\n",
            "Dim after PCA:  (254, 114)\n"
          ]
        }
      ],
      "source": [
        "sil_score = []\n",
        "k_vals = []\n",
        "cost =[]\n",
        "k_max = 9\n",
        "\n",
        "# Get reduced features\n",
        "w_pca = run_pca(w)\n",
        "\n",
        "for k in range(2, k_max + 1):\n",
        "  kmeans1 = KMeans(n_clusters = k).fit(w_pca)#w)\n",
        "  labels = kmeans1.labels_\n",
        "  sil_score.append(silhouette_score(w_pca, labels, metric = 'euclidean'))\n",
        "  k_vals.append(k)\n",
        "\n",
        "for k in range(1, k_max + 2):\n",
        "  kmeans2 = KMeans(n_clusters = k, max_iter = 500).fit(w_pca)\n",
        "  # calculates squared error\n",
        "  # for the clustered points\n",
        "  cost.append(kmeans2.inertia_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-VjHtnh4qOD"
      },
      "source": [
        "Plot the Silhouette Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "0YyDD2knPkOb",
        "outputId": "047e0018-e3ec-422b-ddf0-e722d6a991e0"
      },
      "outputs": [],
      "source": [
        "#sil_name = '50res_fit7_hatsil.png'\n",
        "plt.plot(k_vals, sil_score)\n",
        "plt.ylabel('Silhoutte Score')\n",
        "plt.xlabel('Best K')\n",
        "plt.title('PCA dim from 2048 to 114')\n",
        "#plt.title('fit to round 7')\n",
        "plt.suptitle('ResNet pretrained on ImageNet')\n",
        "#plt.savefig('/content/gdrive/MyDrive/Colab Notebooks/model_charts/{}'.format(sil_name))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzY_S27l4yj-"
      },
      "source": [
        "Plot the Elbow Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "FFpVZ2Gv4x_m",
        "outputId": "2c625ba8-0922-44d9-8f2a-79b6e3ba436a"
      },
      "outputs": [],
      "source": [
        "#elb_name = '50res_7_hatelb.png'\n",
        "\n",
        "# plot the cost against K values\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.plot(range(1, k_max + 2), cost, color ='g', linewidth ='3')\n",
        "plt.title('PCA dim from 2048 to 114')\n",
        "#plt.title('fit to round 7')\n",
        "plt.suptitle('Elbow Curve of Pretrained ResNet (ImageNet)')\n",
        "plt.xlabel(\"K value\")\n",
        "plt.ylabel(\"Squared Error\")\n",
        "\n",
        "#plt.savefig('/content/gdrive/MyDrive/Colab Notebooks/model_charts/{}'.format(elb_name))\n",
        "\n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiIZUsepvvsY"
      },
      "source": [
        "# Apply optimal K with clustering for labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IujNYx435Za",
        "outputId": "9a3f93cf-2be6-4498-f0ad-a916abeda391"
      },
      "outputs": [],
      "source": [
        "# Fit Reduced feature data to 3 clusters and predict classes\n",
        "kmeans = KMeans(n_clusters = 3, random_state = 0).fit(w_pca)\n",
        "clusters = kmeans.fit_predict(w_pca)\n",
        "print(\"cluster center shape: \", kmeans.cluster_centers_.shape)\n",
        "print(\"label shape: \", kmeans.labels_.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhFPtc1C62gG"
      },
      "outputs": [],
      "source": [
        "raw_data = False\n",
        "if raw_data == True:\n",
        "  if m == 'res50':\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(9, 11))\n",
        "    centers = kmeans.cluster_centers_.reshape(3, 368, 284, 3)\n",
        "    for axi, center in zip(ax.flat, centers):\n",
        "        axi.set(xticks=[], yticks=[])\n",
        "        axi.imshow(center*255, interpolation='nearest', cmap=plt.cm.binary)\n",
        "  else:\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(9, 11))\n",
        "    centers = kmeans.cluster_centers_.reshape(3, 368, 284)\n",
        "    for axi, center in zip(ax.flat, centers):\n",
        "        axi.set(xticks=[], yticks=[])\n",
        "        axi.imshow(center, interpolation='nearest', cmap=plt.cm.binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgLiUoPb9zls"
      },
      "source": [
        "Calculate Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELUOXu6j-Hed",
        "outputId": "beb68dbb-ee43-4c70-d260-74358d49a89d"
      },
      "outputs": [],
      "source": [
        "labels = np.zeros_like(kmeans.labels_)\n",
        "for i in range(3):\n",
        "    mask = (kmeans.labels_ == i)\n",
        "    #print(mask)\n",
        "    labels[mask] = mode(y_train_[mask])[0]\n",
        "\n",
        "\n",
        "accuracy_score(y_train_, labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "kvTj5KnVvAUE",
        "outputId": "d5d6f0eb-bbc8-468b-9cbe-392d0e42800c"
      },
      "outputs": [],
      "source": [
        "matrix = confusion_matrix(y_train_, labels)\n",
        "sns.heatmap(matrix, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=[0,1,2],\n",
        "            yticklabels=[0,1,2])\n",
        "plt.ylabel('true label')\n",
        "plt.xlabel('predicted label');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Guv2Y8RcAP5U"
      },
      "source": [
        "Using NHATS label for round 7 un-balanced test set data, fit on Pretrained ReNet50 on ImageNet only using 3 clusters was 79% accurate compared to cluster labels. This set is unbalanced and is over-predicting the most common class. \n",
        "\n",
        "When used on the train_set, which is balanced, the accuracy plummets to ~34%\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "uyZdygGkFIjT",
        "outputId": "0ae69471-8bc6-4eb5-f544-2023bafa2036"
      },
      "outputs": [],
      "source": [
        "#y_pred = kmeans.predict(X_train)\n",
        "fig = plt.figure(figsize = (15,15))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "plt.scatter(w_pca[clusters == 0,0],w_pca[clusters == 0,1],s = 50, c = 'green', label = \"cluster 1\")\n",
        "plt.scatter(w_pca[clusters == 1,0],w_pca[clusters == 1,1],s = 50, c = 'blue', label = \"cluster 2\")\n",
        "plt.scatter(w_pca[clusters == 2,0],w_pca[clusters == 2,1],s = 50, c = 'pink', label = \"cluster 3\")\n",
        "plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1], s = 100, c = \"red\", label = \"centroids\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPgNlnLlHuhKEa3hhz8gzk3",
      "collapsed_sections": [],
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "Presentation_Transfer Learning Kmeans.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1090d3fa925d4038837812e7a5fad35e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d52bdba857c406b99d5140ea8ddce7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d9dee4b836c4c85a65dea21d754a907": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e58225a2f15430398fb0e4c50939172": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33453b104cda4358b73224ae49a9b24c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "626cd0c21f97410f8241b17b208deba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5143400f47143f4ba30c6393bc5a015",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33453b104cda4358b73224ae49a9b24c",
            "value": 102530333
          }
        },
        "806838574b924a878709e07968ee291f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d9dee4b836c4c85a65dea21d754a907",
            "placeholder": "​",
            "style": "IPY_MODEL_1d52bdba857c406b99d5140ea8ddce7f",
            "value": "100%"
          }
        },
        "9fd09081e3a546ac8f42e8b9190f85e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6b11ef609f54bd29ec8f0975933eccb",
            "placeholder": "​",
            "style": "IPY_MODEL_1e58225a2f15430398fb0e4c50939172",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 147MB/s]"
          }
        },
        "b1d9d979190c4543b40fb71308fff837": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_806838574b924a878709e07968ee291f",
              "IPY_MODEL_626cd0c21f97410f8241b17b208deba9",
              "IPY_MODEL_9fd09081e3a546ac8f42e8b9190f85e3"
            ],
            "layout": "IPY_MODEL_1090d3fa925d4038837812e7a5fad35e"
          }
        },
        "c6b11ef609f54bd29ec8f0975933eccb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5143400f47143f4ba30c6393bc5a015": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
