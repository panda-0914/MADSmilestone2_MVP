{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa6L-qwlfHPf"
      },
      "source": [
        "# Supervised Learning: Clock Drawing Image Classification with Convolutional Neural Networks\n",
        "### Stacey Beck and Ian Byrne\n",
        "\n",
        "- Split data into sets of Training (x = image arrays ; y = labels), Test (~10% image arrays), and Validation (~10% of the Training). \n",
        "- Build CNN using Pytorch for Training and Test:\n",
        "  - Specify CUDA\n",
        "  - 2D convolution, Normalization (for faster training), Non-linear Activation Function (ex. RELU), Max Pooling (downsampling to reduce learned parameters).\n",
        "  - Define Layers \n",
        "  - Build Forward and backward pass\n",
        "  - Define optimizer (due to many - deep - nodes) ex) ADAM\n",
        "  - Calculate Loss (BCE)\n",
        "  - Calculate Accuracy, Precision, Recall (Confusion Matrix)\n",
        "  - Plot ROC and print Confusion Matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKcEhDBuf5ow"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtH9tfFdQepN"
      },
      "outputs": [],
      "source": [
        "# General Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import logging\n",
        "import os\n",
        "import tempfile\n",
        "import glob\n",
        "\n",
        "# Pytroch Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchmetrics\n",
        "\n",
        "# To Evaluate model\n",
        "from tqdm import tqdm\n",
        "import torchmetrics\n",
        "from torchmetrics import ConfusionMatrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# To visualize model\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from skimage.io import imread\n",
        "\n",
        "# To split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5jwtXk7qv9-"
      },
      "source": [
        "# Build CNN Model using Pytorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nKizV2h4lMH"
      },
      "source": [
        "### Building and Training\n",
        "Architecture choices influenced from: \n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2018/12/guide-convolutional-neural-network-cnn/\n",
        "\n",
        "https://medium.datadriveninvestor.com/five-powerful-cnn-architectures-b939c9ddd57b\n",
        "\n",
        "https://towardsdatascience.com/how-does-sparse-convolution-work-3257a0a8fd1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OOYf4s0smrq"
      },
      "outputs": [],
      "source": [
        "epochs = 2\n",
        "train_batch_size = 8\n",
        "val_batch = 4\n",
        "test_batch = 1\n",
        "learning_rate = 1e-3\n",
        "kernel_size = 3\n",
        "stride = 1\n",
        "padding = 1 #2*floor(3/2)\n",
        "weight_decay = 1e-5\n",
        "# Define file extension to use for new data saves\n",
        "extension_ = \"res_netfp\"\n",
        "# Normalize data if rgb and set rgb_val to True to convert \n",
        "normalize_ = 'True'\n",
        "# Define which round to get data from\n",
        "rnd = 7\n",
        "# Define model extensions for naming file (which model do we want to train on)\n",
        "model_ext = \"3\"\n",
        "# m = 'First model'\n",
        "# m = 'pre-trained'\n",
        "#m = 'pre-trained-res'\n",
        "m = 'resnet'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ypf_eiS8Eghk"
      },
      "outputs": [],
      "source": [
        "def open_dict(path):\n",
        "    \"\"\"Takes in path and opens file\"\"\"\n",
        "\n",
        "    cust_file = open(path, \"r\")\n",
        "    contents = cust_file.read()\n",
        "    dictionary = ast.literal_eval(contents)\n",
        "    cust_file.close()\n",
        "\n",
        "    return dictionary\n",
        "\n",
        "\n",
        "dictionarytr = open_dict(\n",
        "    \"/content/gdrive/MyDrive/Data/Dictionaries/score_dicts/tr_scor_dict_bal.txt\"\n",
        ")\n",
        "dictionaryv = open_dict(\n",
        "    \"/content/gdrive/MyDrive/Data/Dictionaries/score_dicts/val_scor_dict_nobal.txt\"\n",
        ")\n",
        "dictionaryts = open_dict(\n",
        "    \"/content/gdrive/MyDrive/Data/Dictionaries/score_dicts/tst_scor_dict_nobal.txt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54Zv5Nsk-R-U"
      },
      "outputs": [],
      "source": [
        "for id, val in dictionarytr.items():\n",
        "  print(\"Round {} length is {}\".format(str(id), str(len(val))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUo2KZ_UYhYE"
      },
      "outputs": [],
      "source": [
        "class ResizedClocks:\n",
        "    # Resized clock drawing dataset\n",
        "\n",
        "    def __init__(self, round, round_labels, rgb=None, transform=None):\n",
        "\n",
        "        # Args:\n",
        "        # round (int): Round to grab images from.\n",
        "        # values (list of tuples): Corresponding values for the round.\n",
        "\n",
        "        self.round = round\n",
        "        self.vals = round_labels\n",
        "        self.base_path = '/content/gdrive/MyDrive/Data/Nhats Dataset/NHATS_R11_ClockDrawings_V2'\n",
        "        self.transform = transform\n",
        "        self.rgb = rgb\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.vals)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        spid = self.vals[idx][0]\n",
        "        label = torch.tensor(int(self.vals[idx][1]))\n",
        "        \n",
        "        # Try different file extensions\n",
        "        possible_files = [\n",
        "            f\"{self.base_path}/{spid}.tif\",\n",
        "            f\"{self.base_path}/{spid}.jpg\",\n",
        "            f\"{self.base_path}/{spid}.png\",\n",
        "            f\"{self.base_path}/{spid}.jpeg\"\n",
        "        ]\n",
        "        \n",
        "        image_path = None\n",
        "        for file_path in possible_files:\n",
        "            if os.path.exists(file_path):\n",
        "                image_path = file_path\n",
        "                break\n",
        "        \n",
        "        if image_path is None:\n",
        "            return None  # File not found\n",
        "\n",
        "        try:\n",
        "            im = Image.open(image_path)\n",
        "\n",
        "            if self.rgb:\n",
        "                gray = im.convert('RGB')\n",
        "            else:\n",
        "                gray = im.convert('1')\n",
        "\n",
        "            resized = gray.resize((160, 207))\n",
        "            im_arr = np.float32(np.array(resized))\n",
        "\n",
        "            if self.transform:\n",
        "                im_arr = self.transform(im_arr)\n",
        "\n",
        "            return im_arr, label\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {image_path}: {e}\")\n",
        "            return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cco7mnKoYwEX"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "  \"\"\"From pytorch - way to bypass corrupt or non-existent data\"\"\"\n",
        "  batch = list(filter(lambda x: x is not None, batch))\n",
        "  return torch.utils.data.dataloader.default_collate(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn8N9D4YZJcR"
      },
      "outputs": [],
      "source": [
        "# initialize transformation: data to tensor and normalize\n",
        "# Could probably resize using torch.transforms\n",
        "if normalize_ == \"True\":\n",
        "    processes = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    )\n",
        "    rgb_val = \"True\"\n",
        "else:\n",
        "    processes = transforms.ToTensor()\n",
        "    rgb_val = None\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bz4e3izRZMJx"
      },
      "outputs": [],
      "source": [
        "train_set = ResizedClocks(rnd, dictionarytr[rnd], transform = processes, rgb = rgb_val)\n",
        "val_set = ResizedClocks(rnd, dictionaryv[rnd], transform = processes, rgb = rgb_val)\n",
        "test_set = ResizedClocks(rnd, dictionaryts[rnd], transform = processes, rgb = rgb_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPc4Tg8yZPiE"
      },
      "outputs": [],
      "source": [
        "# Define Dataloaders for the network\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size = train_batch_size, shuffle = True, num_workers = 6, collate_fn=collate_fn) \n",
        "validate_loader = torch.utils.data.DataLoader(val_set, batch_size = val_batch, shuffle = True, num_workers = 6, collate_fn=collate_fn) #64, 8,1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kne45tSsQvFQ"
      },
      "outputs": [],
      "source": [
        "# For round 10, there are some corrupt data that when batched at size 1 is not taken\n",
        "# care of by the collate function, but Nonechucks library skips the missing data and \n",
        "# moves on, replacing that missing data index with the next piece of data\n",
        "# could probably just use this in place of collate for all the loading\n",
        "if rnd == 10:\n",
        "  !pip install nonechucks\n",
        "  import nonechucks as nc\n",
        "  test_set_safe = nc.SafeDataset(test_set)\n",
        "  test_loader = torch.utils.data.DataLoader(test_set_safe, batch_size = test_batch, shuffle = False)\n",
        "else:\n",
        "  test_loader = torch.utils.data.DataLoader(test_set, batch_size = test_batch, shuffle = False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAovKkRXFU4j"
      },
      "outputs": [],
      "source": [
        "def set_model(m, model_ext, device):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"First Model training on GPU\")\n",
        "\n",
        "        if m == \"First model\":\n",
        "            # Create model object\n",
        "            model = ConvNet()\n",
        "            model = model.to(device)  # (float).cuda()\n",
        "\n",
        "        elif m == \"pre-trained\":\n",
        "            mPATH = \"/content/gdrive/MyDrive/Colab Notebooks/Models/cnn_512_662.model{}\".format(\n",
        "                model_ext\n",
        "            )\n",
        "            model = ConvNet()\n",
        "            model.load_state_dict(torch.load(mPATH))\n",
        "            model.to(device)\n",
        "            print(\"New Model{} training on GPU\".format(model_ext))\n",
        "\n",
        "        elif m == \"resnet\":\n",
        "            model = models.resnet50(pretrained=True)\n",
        "            num_ftrs = model.fc.in_features\n",
        "            model.fc = nn.Linear(num_ftrs, 6)\n",
        "            model = model.to(device)\n",
        "            print(\"RESNET Model training on GPU\")\n",
        "\n",
        "        elif m == \"pre-trained-res\":\n",
        "            mPATH = \"/content/gdrive/MyDrive/Colab Notebooks/Models/cnn_512_662.model{}\".format(\n",
        "                model_ext\n",
        "            )\n",
        "            model = models.resnet50()\n",
        "            num_ftrs = model.fc.in_features\n",
        "            model.fc = nn.Linear(num_ftrs, 6)\n",
        "            model.load_state_dict(torch.load(mPATH))\n",
        "            model.to(device)\n",
        "            print(\"New Model{} training on GPU\".format(model_ext))\n",
        "\n",
        "    else:\n",
        "        print(\"CUDA is not available. Turn on GPU\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiY5mGPbZxDV"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_pred, y_test):\n",
        "  # Calculating model accuracy at each epoch \n",
        "  y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "  _, y_pred_prob = torch.max(y_pred_softmax, dim = 1)\n",
        "  correct_pred = (y_pred_prob == y_test).float()\n",
        "  acc = correct_pred.sum() / len(correct_pred)\n",
        "  acc = torch.round(acc * 100)\n",
        "\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrUu9AXiZ0SL"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        # without considering batch size: Input shape : (None,368, 284, 1) , parameters: (3*3*1*16+16) = 160\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=16,  # one input channel gray scale, 16 filters out\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "        )  # Out:(None,386, 284, 16). ### TRY kernel 7x7 padding 3\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1\n",
        "        )  # params: (3*3*16*32+32) = 4640\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)  # Out: (None, 184, 142, 32)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1\n",
        "        )  # params: (3*3*16*32+32) = 4640\n",
        "        self.conv4 = nn.Conv2d(\n",
        "            in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1\n",
        "        )  # params: (3*3*32*32+32) = 9248\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)  # Output shape = (None, 92, 71, 64)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 128,\n",
        "        # kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248\n",
        "        self.conv6 = nn.Conv2d(\n",
        "            in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1\n",
        "        )  # params: (3*3*32*32+32) = 9248\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)  # Output shape = (None, 46, 35, 128)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.do2 = nn.Dropout(0.3)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc1 = nn.Linear(\n",
        "            128 * 64 * 82, 60\n",
        "        )  # most recent original size of: 512, 662 -->64 x 82\n",
        "        self.do3 = nn.Dropout(0.4)  # 40 % probability\n",
        "        # self.fc3 = nn.Linear(60, 30)\n",
        "        self.fc2 = nn.Linear(60, 6)  # left with 3 for the three classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(self.pool1(F.relu(self.conv2(F.relu(self.conv1(x))))))\n",
        "        x = self.bn2(self.pool2(F.relu(self.conv4(F.relu(self.conv3(x))))))\n",
        "        # x = self.bn3(self.pool3(F.relu(self.conv6(F.relu(self.conv5(x))))))\n",
        "        x = self.bn3(self.pool3(F.relu(self.conv6((x)))))\n",
        "        x = self.do2(x)\n",
        "        x = x.view(x.size(0), 128 * 64 * 82)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.do3(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8J29SCjraCcu"
      },
      "outputs": [],
      "source": [
        "def train_val_model(epochs):\n",
        "    for epoch in range(1, epochs + 1):\n",
        "\n",
        "        train_epoch_loss = 0\n",
        "        train_epoch_acc = 0\n",
        "\n",
        "        # set model in training mode\n",
        "        model.train()\n",
        "        print(\"\\nEpoch$ : %d\" % epoch)\n",
        "        for x_train_batch, y_train_batch in tqdm(train_loader):\n",
        "            x_train_batch = x_train_batch.to(\n",
        "                device\n",
        "            )  # (float).to(device) # for GPU support\n",
        "            y_train_batch = y_train_batch.to(device)\n",
        "\n",
        "            # print(x_train_batch.shape)\n",
        "\n",
        "            # sets gradients to 0 to prevent interference with previous epoch\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass through NN\n",
        "            y_train_pred = model(x_train_batch)  # .to(float)\n",
        "            train_loss = criterion(y_train_pred, y_train_batch)\n",
        "            train_acc = accuracy(y_train_pred, y_train_batch)\n",
        "\n",
        "            # Backward pass, updating weights\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            train_epoch_loss += train_loss.item()\n",
        "            train_epoch_acc += train_acc.item()\n",
        "\n",
        "        with torch.set_grad_enabled(False):\n",
        "            val_epoch_loss = 0\n",
        "            val_epoch_acc = 0\n",
        "\n",
        "            model.eval()\n",
        "            for x_val_batch, y_val_batch in tqdm(validate_loader):\n",
        "\n",
        "                x_val_batch = x_val_batch.to(device)  # .to(float)\n",
        "                y_val_batch = y_val_batch.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                y_val_pred = model(x_val_batch)  # .to(float)\n",
        "                val_loss = criterion(y_val_pred, y_val_batch)\n",
        "                val_acc = accuracy(y_val_pred, y_val_batch)\n",
        "\n",
        "                val_epoch_loss += val_loss.item()\n",
        "                val_epoch_acc += val_acc.item()\n",
        "\n",
        "        # Prevent plateauing validation loss\n",
        "        # scheduler.step(val_epoch_loss/len(validate_loader))\n",
        "\n",
        "        loss_stats[\"train\"].append(train_epoch_loss / len(train_loader))\n",
        "        loss_stats[\"val\"].append(val_epoch_loss / len(validate_loader))\n",
        "        accuracy_stats[\"train\"].append(train_epoch_acc / len(train_loader))\n",
        "        accuracy_stats[\"val\"].append(val_epoch_acc / len(validate_loader))\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch+0:03}: Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(validate_loader):.5f}\"\n",
        "        )\n",
        "        print(\n",
        "            f\"Train Acc: {train_epoch_acc/len(train_loader):.3f} | Val Acc: {val_epoch_acc/len(validate_loader):.3f}\"\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE2oVsUSZgbl"
      },
      "outputs": [],
      "source": [
        " # Set to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFAXymkCZ8aX"
      },
      "outputs": [],
      "source": [
        "# Get model\n",
        "model = set_model(m, model_ext, device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)#, momentum = 0.9) #or ADAM/ momentum\n",
        "# optimizer = torch.optim.SGD(\n",
        "#     model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
        "# )\n",
        "\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size = 4, gamma=0.1)\n",
        "# scheduler = ReduceLROnPlateau(optimizer, \"min\", patience=4)\n",
        "\n",
        "accuracy_stats = {\"train\": [], \"val\": []}\n",
        "\n",
        "loss_stats = {\"train\": [], \"val\": []}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5xpaSNBrNR5"
      },
      "outputs": [],
      "source": [
        "train_val_model(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SunqC9OGaO_r"
      },
      "outputs": [],
      "source": [
        "# added learning rate decay after 3rd epoch\n",
        "# 1st: round 1\n",
        "# 2nd: round 5\n",
        "# 3rd: round 6 best so far\n",
        "# 4th: round 7\n",
        "# 5th (model) saved training on 9\n",
        "# 6th: round 2\n",
        "# 7th round 8\n",
        "# 8th round 3\n",
        "# 9th round 4\n",
        "# 10th round 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHUjtLim2mdN"
      },
      "source": [
        "# Visualize the Training and Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv3SoFHj2ssM"
      },
      "outputs": [],
      "source": [
        "# Create dataframes\n",
        "train_val_acc_df = pd.DataFrame.from_dict(accuracy_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
        "train_val_loss_df = pd.DataFrame.from_dict(loss_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs('/content/gdrive/MyDrive/Colab_Notebooks/acc_loss', exist_ok=True)\n",
        "os.makedirs('/content/gdrive/MyDrive/Colab_Notebooks/model_charts', exist_ok=True)\n",
        "\n",
        "train_val_acc_df.to_csv('/content/gdrive/MyDrive/Colab_Notebooks/acc_loss/acc{}.csv'.format(extension_), index = False)\n",
        "train_val_loss_df.to_csv('/content/gdrive/MyDrive/Colab_Notebooks/acc_loss/loss{}.csv'.format(extension_), index = False)\n",
        "# Plot the dataframes\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,7))\n",
        "sns.lineplot(data=train_val_acc_df, x = \"epochs\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Train-Val Accuracy/Epoch')\n",
        "sns.lineplot(data=train_val_loss_df, x = \"epochs\", y=\"value\", hue=\"variable\", ax=axes[1]).set_title('Train-Val Loss/Epoch')\n",
        "fig.savefig('/content/gdrive/MyDrive/Colab_Notebooks/model_charts/acc_loss{}.png'.format(extension_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITYjyxcK2a9P"
      },
      "source": [
        "# Evaluate the model using Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxkr2sXqqy6x"
      },
      "outputs": [],
      "source": [
        "# Calculate performance\n",
        "y_test = torch.tensor([])\n",
        "test_acc = torchmetrics.Accuracy()\n",
        "\n",
        "with torch.set_grad_enabled(False):\n",
        "  model.eval()\n",
        "  #model.to(float)\n",
        "  for batches in tqdm(test_loader):\n",
        "    x_test, y_test = batches\n",
        "    x_test = x_test.to(device)\n",
        "    y_test = y_test.to(device)\n",
        "    y_pred = model(x_test)\n",
        "    test_acc(y_pred.cpu(), y_test.cpu())\n",
        "    total_test_acc = test_acc.compute()\n",
        "  print('test acc: ', total_test_acc)\n",
        "  test_acc.reset()\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4OOWwEWrW2-"
      },
      "source": [
        "## Create Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QROmDemn_QeY"
      },
      "outputs": [],
      "source": [
        "all_pred = []\n",
        "all_preds = torch.tensor([])\n",
        "y_test = torch.tensor([])\n",
        "with torch.set_grad_enabled(False):\n",
        "  model.eval()\n",
        "  for x_test_batch, y_test_batch in tqdm(test_loader):\n",
        "    x_test_batch = x_test_batch.to(device)#.to(float).to(device)\n",
        "    y_test_pred = model(x_test_batch)\n",
        "    _, y_pred_probs = torch.max(y_test_pred, dim = 1)\n",
        "    all_pred.append(y_pred_probs.cpu().numpy())\n",
        "    all_preds = torch.cat((all_preds.cpu(), y_pred_probs.cpu()),dim = 0)\n",
        "    y_test = torch.cat((y_test, y_test_batch), dim = 0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bI5PGwvU_SZq"
      },
      "outputs": [],
      "source": [
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_test, all_pred))#.rename(columns=idx2class, index=idx2class)\n",
        "sns.heatmap(confusion_matrix_df, annot=True, fmt=\".2f\", cmap='BuGn')\n",
        "plt.xlabel(\"prediction\")\n",
        "plt.ylabel(\"label (ground truth)\")\n",
        "plt.savefig('/content/gdrive/MyDrive/Colab_Notebooks/model_charts/CMTX{}.png'.format(extension_))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqMBs_YS_U0U"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "#class_names = [\"Possible Dementia\", \"Likely Dementia\", \"No Dementia\"]\n",
        "class_vals = [0,1,2]\n",
        "\n",
        "cr = classification_report(y_test, all_pred, class_vals, output_dict = True)\n",
        "try:\n",
        "    cr_file = open('/content/gdrive/MyDrive/Colab_Notebooks/model_charts/cr{}.txt'.format(extension_), 'wt')\n",
        "    cr_file.write(str(cr))\n",
        "    cr_file.close()\n",
        "  \n",
        "except:\n",
        "    print(\"Unable to write to file\")\n",
        "print(classification_report(y_test, all_pred, class_vals))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhz6gXGHpcMB"
      },
      "source": [
        "# Plot ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nQrbRJ9_Xoh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt \n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "\n",
        "target= [0, 1, 2]\n",
        "\n",
        "# set plot figure size\n",
        "fig, c_ax = plt.subplots(1,1, figsize = (12, 8))\n",
        "\n",
        "# function for scoring roc auc score for multi-class\n",
        "def multiclass_roc_auc_score(y_test1, all_pred1, average=\"macro\"):\n",
        "    lb = LabelBinarizer()\n",
        "    lb.fit(y_test1)\n",
        "    y_test1 = lb.transform(y_test1)\n",
        "    all_pred1 = lb.transform(all_pred1)\n",
        "\n",
        "    for (idx, c_label) in enumerate(target):\n",
        "        fpr, tpr, thresholds = roc_curve(y_test1[:,idx].astype(int), all_pred1[:,idx])\n",
        "        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
        "    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n",
        "    return roc_auc_score(y_test1, all_pred1, average=average)\n",
        "\n",
        "\n",
        "print('ROC AUC score:', multiclass_roc_auc_score(y_test, all_pred))\n",
        "\n",
        "c_ax.legend()\n",
        "c_ax.set_xlabel('False Positive Rate')\n",
        "c_ax.set_ylabel('True Positive Rate')\n",
        "plt.savefig('/content/gdrive/MyDrive/Colab_Notebooks/model_charts/roc{}.png'.format(extension_))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8DS8yc9YMQg"
      },
      "outputs": [],
      "source": [
        "# precision recall curve\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "\n",
        "# Use label_binarize to be multi-label like settings\n",
        "y = y_test.numpy()\n",
        "Y = label_binarize(y, classes=[0, 1, 2])\n",
        "Y_pred = label_binarize(all_pred, classes=[0, 1, 2])\n",
        "n_classes = Y.shape[1]\n",
        "\n",
        "precision = dict()\n",
        "recall = dict()\n",
        "for i in range(n_classes):\n",
        "    precision[i], recall[i], _ = precision_recall_curve(Y[:, i],\n",
        "                                                        Y_pred[:, i])\n",
        "    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
        "    \n",
        "plt.xlabel(\"recall\")\n",
        "plt.ylabel(\"precision\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.title(\"precision vs. recall curve\")\n",
        "plt.savefig('/content/gdrive/MyDrive/Colab_Notebooks/model_charts/auc_pr{}.png'.format(extension_))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKR_i_oebCi2"
      },
      "source": [
        "## Save the GPU CNN Model\n",
        "Also includes loading on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTEwjKcbbAlJ"
      },
      "outputs": [],
      "source": [
        "# Save GPU model\n",
        "model_name = 'cnn_1run.model{}'.format(extension_)\n",
        "PATH = \"/content/gdrive/MyDrive/Colab_Notebooks/{}\".format(model_name)\n",
        "torch.save(model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm-xL-D6bcp6"
      },
      "outputs": [],
      "source": [
        "\"\"\"# Load GPU model\n",
        "device = torch.device(\"cuda\")\n",
        "model = TheModelClass(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.to(device)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Z8UDiRbLUG8"
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    class_names = [0,1,2]\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(validate_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                if j < len(preds):\n",
        "                    ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                    if inputs.cpu().data[j].shape[0] == 3:  # RGB\n",
        "                        imshow(inputs.cpu().data[j])\n",
        "                    else:  # Grayscale\n",
        "                        plt.imshow(inputs.cpu().data[j].squeeze(), cmap='gray')\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "visualize_model(model)  "
      ]
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0
}