{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ian-byrne/MADSmilestone2/blob/main/multimodel1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WJ-YY1RBAgi"
      },
      "source": [
        "Multiple Model Option"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1FoRQ6XYh-E",
        "outputId": "19d969f0-4c87-46b2-9a8c-5e034912293e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Flfv_Cqa4at-"
      },
      "outputs": [],
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/ian-byrne/MADSmilestone2.git\n",
        "# Change directory into cloned repo\n",
        "%cd MADSmilestone2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0ouIghrj2PN7"
      },
      "outputs": [],
      "source": [
        "# !git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "UyEMNGgmWTFo"
      },
      "outputs": [],
      "source": [
        "#!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PogN9gqzcOEx",
        "outputId": "2ea734ae-38c4-4afb-ad1e-06148be4a97b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.6) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ]
        }
      ],
      "source": [
        "# General Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import os\n",
        "# Custom Libraries\n",
        "import Loading.load_data as ld\n",
        "\n",
        "# Pytroch Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "# To Evaluate model\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# To visualize model\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from skimage.io import imread\n",
        "\n",
        "# To split the data\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GcxL35AcBpHR"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.activation import ReLU\n",
        "# Set to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Gq2Fj5cGUvlm"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "# Modified dataset class to use local files\n",
        "class ResizedClocks(Dataset):\n",
        "    #Resized clock drawing dataset\n",
        "\n",
        "    def __init__(self, image_folder_path, round_labels):\n",
        "        \n",
        "       # Args:\n",
        "           # image_folder_path (str): Path to the folder containing images. \n",
        "           # round_labels (list of tuples): Corresponding values for the round.\n",
        "        \n",
        "        self.image_folder_path = image_folder_path\n",
        "        self.vals = round_labels\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.vals)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        spid = self.vals[idx][0]\n",
        "        label = self.vals[idx][1]\n",
        "        \n",
        "        # Construct the image file path\n",
        "        image_path = os.path.join(self.image_folder_path, f\"{spid}.tif\")\n",
        "        \n",
        "        try:\n",
        "          # Load image directly from local path\n",
        "          im = Image.open(image_path)\n",
        "\n",
        "          gray = im.convert('1')\n",
        "          resized = gray.resize((160, 207)) \n",
        "          im_arr = np.array(resized).astype(int)\n",
        "\n",
        "          sample = {'image': im_arr, 'label': label}\n",
        "\n",
        "          return sample\n",
        "          \n",
        "        except Exception as e:\n",
        "          print(f\"Error loading image {image_path}: {e}\")\n",
        "          pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "t1JK1NXXV1DZ"
      },
      "outputs": [],
      "source": [
        "file = open(\"Data/Dictionaries/score_dicts/tr_scor_dict_bal.txt\", \"r\")\n",
        "\n",
        "contents = file.read()\n",
        "im_scores = ast.literal_eval(contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tAVQQwk8PrPG"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "learning_rate = .001\n",
        "kernel_size = 3\n",
        "stride = 1\n",
        "padding = 1 #2*floor(3/2)\n",
        "\n",
        "accuracy_stats = {\n",
        "    'train': [],\n",
        "    'val': []\n",
        "}\n",
        "\n",
        "loss_stats = {\n",
        "    'train': [],\n",
        "    'val': []\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNHnJYysXnqV",
        "outputId": "b957b173-c2c8-4913-ec06-399c2c4449e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(23621, 1, 368, 284)\n"
          ]
        }
      ],
      "source": [
        "path = \"/content/gdrive/MyDrive/numpy_files/Score_data/\"\n",
        "training_data, y_train_tensor = ld.load_np_files(path+\"train_score_im.npy\", path+\"train_score_labels.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu8kAT744xRy",
        "outputId": "8edfdb3c-6c0f-4a38-e241-49ed48a8d6a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2544, 1, 368, 284)\n",
            "(2541, 1, 368, 284)\n"
          ]
        }
      ],
      "source": [
        "validation_data, y_val_tensor = ld.load_np_files(path+\"val_score_im.npy\", path+\"val_score_labels.npy\")\n",
        "test_data, y_test_tensor = ld.load_np_files(path+\"tst_score_im.npy\", path+\"tst_score_labels.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z1cMZCzp9wK2"
      },
      "outputs": [],
      "source": [
        "y_train_tensor = y_train_tensor.to(torch.long)\n",
        "y_test_tensor = y_test_tensor.to(torch.long)\n",
        "y_test_tensor = y_test_tensor.to(torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqI32aaA_0yU",
        "outputId": "f13583fe-827e-4977-d825-165d011595d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "IjYDHApzc07a"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size = batch_size, shuffle = True) \n",
        "validate_loader = torch.utils.data.DataLoader(validation_data, batch_size = batch_size, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = False)\n",
        "#Labels \n",
        "#classes = (0.0, 1.0, 2.0, 3.0, 4.0, 5.0)\n",
        "classes = (0, 1, 2, 3, 4, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lSbSa2U3Bo72"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    # without considering batch size: Input shape : (None,368, 284, 1) , parameters: (3*3*1*16+16) = 160\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 16, # one input channel gray scale, 16 filters out\n",
        "                            kernel_size = 3, stride = 1, padding = 1) #Out:(None,386, 284, 16)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) #params: (3*3*16*32+32) = 4640                        \n",
        "    self.pool1 = nn.MaxPool2d(2, 2) #Out: (None, 184, 142, 32)\n",
        "    self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) #params: (3*3*16*32+32) = 4640    \n",
        "    self.conv4 = nn.Conv2d(in_channels = 64, out_channels = 64, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248                     \n",
        "    self.pool2 = nn.MaxPool2d(2, 2) #Output shape = (None, 92, 71, 64)\n",
        "    self.bn2 = nn.BatchNorm2d(64) \n",
        "\n",
        "    self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 128, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248 \n",
        "    self.conv6 = nn.Conv2d(in_channels = 128, out_channels = 128, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248\n",
        "    self.pool3 = nn.MaxPool2d(2, 2) #Output shape = (None, 46, 35, 128)\n",
        "    self.bn3 = nn.BatchNorm2d(128)\n",
        "    \n",
        "    # Fully connected layer\n",
        "    self.fc1 = nn.Linear(128*46*35,6)\n",
        "    #self.fc2 = nn.Linear(120, 60)\n",
        "    #self.fc3 = nn.Linear(60, 30)\n",
        "    #self.fc4 = nn.Linear(30, 3) # left with 3 for the three classes \n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn1(self.pool1(F.relu(self.conv2(F.relu(self.conv1(x))))))\n",
        "    x = self.bn2(self.pool2(F.relu(self.conv4(F.relu(self.conv3(x))))))\n",
        "    x = self.bn3(self.pool3(F.relu(self.conv6(F.relu(self.conv5(x))))))\n",
        "    x = x.view(x.size(0),128*46*35)\n",
        "    x = self.fc1(x)\n",
        "\n",
        "\n",
        "    return x "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uRLTUIbpBoWQ"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_pred, y_test):\n",
        "  y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "  _, y_pred_prob = torch.max(y_pred_softmax, dim = 1)\n",
        "  \n",
        "  #y_preds = y_pred.argmax(dim=1)\n",
        "\n",
        "  correct_pred = (y_pred_prob == y_test).float()\n",
        "  #print(\"correct sum: \", correct_pred.sum())\n",
        "  #print('correct total length: ', len(correct_pred))\n",
        "  #print(correct_pred)\n",
        "  acc = correct_pred.sum() / len(correct_pred)\n",
        "  \n",
        "  #acc = correct_pred.sum().float() / float( y_test.size(0) )\n",
        "\n",
        "  acc = torch.round(acc * 100)\n",
        "\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvp-oYUuBozP",
        "outputId": "3dab6316-dce5-46d5-d14a-16b1dae5627b"
      },
      "outputs": [],
      "source": [
        "# Create model object \n",
        "model = ConvNet()\n",
        "if torch.cuda.is_available():\n",
        "    model = model.to(torch.double).cuda()\n",
        "    print('Model training on GPU')\n",
        "else:\n",
        "    print(\"CUDA is not available. Training on CPU...\")\n",
        "\n",
        "#for param in model.parameters():\n",
        "  #print(str(param.data.numpy().shape)+'\\n')\n",
        "  #print(\"weights fc1: \", model.fc1.weight)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "\n",
        "# Optimizer (can use SGD or ADAM)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)#, momentum = 0.9) #or ADAM/ momentum\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9) #or ADAM/ momentum\n",
        "\n",
        "print(model) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "N5qNtmj2Bop7"
      },
      "outputs": [],
      "source": [
        "def train_val_model(epochs):\n",
        "  for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # TRAINING ********************************\n",
        "    train_epoch_loss = 0\n",
        "    train_epoch_acc = 0\n",
        "\n",
        "    # set model in training mode (recommended)\n",
        "    model.train()\n",
        "\n",
        "    # Double check\n",
        "    tr_run_loss=0\n",
        "    tr_correct=0\n",
        "    tr_total=0\n",
        "    train_accu = []\n",
        "    train_losses = []\n",
        "    \n",
        "    print('\\nEpoch$ : %d'%epoch)\n",
        "    for x_train_batch, y_train_batch in tqdm(train_loader):\n",
        "        x_train_batch = x_train_batch.to(torch.double).to(device) # for GPU support\n",
        "        y_train_batch = y_train_batch.to(torch.long).to(device) \n",
        "\n",
        "        #print(x_train_batch.shape)\n",
        "\n",
        "        # sets gradients to 0 to prevent interference with previous epoch\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass through NN\n",
        "        y_train_pred = model(x_train_batch)\n",
        "        train_loss = criterion(y_train_pred, y_train_batch)\n",
        "        train_acc = accuracy(y_train_pred, y_train_batch)\n",
        "\n",
        "        # Backward pass, updating weights\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        train_epoch_loss += train_loss.item()\n",
        "        train_epoch_acc += train_acc.item()\n",
        "\n",
        "        # Double check scores\n",
        "        tr_run_loss += train_loss.item()\n",
        "        \n",
        "        _, predicted = y_train_pred.max(1)\n",
        "        tr_total += y_train_batch.size(0)\n",
        "        tr_correct += predicted.eq(y_train_batch).sum().item()\n",
        "       \n",
        "    tr_loss = tr_run_loss/len(train_loader)\n",
        "    accu = 100.*tr_correct/tr_total\n",
        "   \n",
        "    train_accu.append(accu)\n",
        "    train_losses.append(tr_loss)\n",
        "    print('Train Loss: %.3f | Train Accuracy: %.3f'%(tr_loss,accu))\n",
        "    # VALIDATION****************************************   \n",
        "    \n",
        "    with torch.set_grad_enabled(False):\n",
        "        val_epoch_loss = 0\n",
        "        val_epoch_acc = 0\n",
        "\n",
        "        # Double check\n",
        "        val_run_loss=0\n",
        "        val_correct=0\n",
        "        val_total=0\n",
        "        val_accu = []\n",
        "        val_losses = []\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        for x_val_batch, y_val_batch in tqdm(validate_loader):\n",
        "      \n",
        "            x_val_batch =  x_val_batch.to(torch.double).to(device)\n",
        "            y_val_batch = y_val_batch.to(torch.long).to(device)\n",
        "                \n",
        "            # Forward pass\n",
        "            y_val_pred = model(x_val_batch)   \n",
        "            val_loss = criterion(y_val_pred, y_val_batch)\n",
        "            val_acc = accuracy(y_val_pred, y_val_batch)\n",
        "                \n",
        "            val_epoch_loss += val_loss.item()\n",
        "            val_epoch_acc += val_acc.item()\n",
        "\n",
        "            # Double check\n",
        "            \n",
        "            val_run_loss += val_loss.item()\n",
        "        \n",
        "            _, predictedv = y_val_pred.max(1)\n",
        "            val_total += y_train_batch.size(0)\n",
        "            val_correct += predictedv.eq(y_val_batch).sum().item()\n",
        "        \n",
        "        vl_loss = val_run_loss/len(validate_loader)\n",
        "        accuv = 100.*val_correct/val_total\n",
        "    \n",
        "        val_accu.append(accuv)\n",
        "        val_losses.append(vl_loss)\n",
        "        print('Validation Loss: %.3f | Validation Accuracy: %.3f'%(vl_loss,accuv))\n",
        "\n",
        "\n",
        "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
        "    loss_stats['val'].append(val_epoch_loss/len(validate_loader))\n",
        "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
        "    accuracy_stats['val'].append(val_epoch_acc/len(validate_loader))\n",
        "    \n",
        "    print(f'Epoch {epoch+0:03}: Train Loss: {train_epoch_loss/len(train_loader):.5f} | \\\n",
        "    Val Loss: {val_epoch_loss/len(validate_loader):.5f}')\n",
        "\n",
        "    print(f'Train Acc: {train_epoch_acc/len(train_loader):.3f} | \\\n",
        "    Val Acc: {val_epoch_acc/len(validate_loader):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKoBD-EJIQL-",
        "outputId": "d159debb-a13f-452e-f01e-0808e2972053"
      },
      "outputs": [],
      "source": [
        "train_val_model(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "BQIPgSt4IQE7",
        "outputId": "8203a36d-687c-4399-fb8c-cff0c453779a"
      },
      "outputs": [],
      "source": [
        "# Create dataframes\n",
        "train_val_acc_df = pd.DataFrame.from_dict(accuracy_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
        "train_val_loss_df = pd.DataFrame.from_dict(loss_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
        "# train_val_acc_df.to_csv('/content/gdrive/MyDrive/Colab Notebooks/acc_loss/acc.csv', index = False)\n",
        "# train_val_loss_df.to_csv('/content/gdrive/MyDrive/Colab Notebooks/acc_loss/loss.csv', index = False)\n",
        "# Plot the dataframes\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,7))\n",
        "sns.lineplot(data=train_val_acc_df, x = \"epochs\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Train-Val Accuracy/Epoch')\n",
        "sns.lineplot(data=train_val_loss_df, x = \"epochs\", y=\"value\", hue=\"variable\", ax=axes[1]).set_title('Train-Val Loss/Epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Ai0YQ-zcIP9M"
      },
      "outputs": [],
      "source": []
    }
  ]
}

